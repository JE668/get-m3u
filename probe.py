import os
import subprocess
import json
import time
import concurrent.futures
import requests
import socket
from urllib.parse import urlparse
from datetime import datetime

# ===============================
# 1. é…ç½®åŒº
# ===============================
SOURCE_M3U_FILE = "source-m3u.txt"
LOG_FILE = "log.txt"
TARGET_REPO = "JE668/iptv-api"
TARGET_WORKFLOW = "main.yml"
TRIGGER_TOKEN = os.environ.get("PAT_TOKEN", "")

# IP ä¿¡æ¯ç¼“å­˜ï¼Œé˜²æ­¢é‡å¤è¯·æ±‚ API å¯¼è‡´å°ç¦
IP_CACHE = {}

# ===============================
# 2. æ ¸å¿ƒåŠŸèƒ½å‡½æ•°
# ===============================

def get_ip_info(url):
    """è·å– IP çš„åœ°ç†ä½ç½®å’Œè¿è¥å•†ä¿¡æ¯"""
    try:
        hostname = urlparse(url).hostname
        ip = socket.gethostbyname(hostname)
        if ip in IP_CACHE:
            return IP_CACHE[ip]
        
        # é¢‘ç‡æ§åˆ¶ï¼šip-api é™åˆ¶æ¯åˆ†é’Ÿ45æ¬¡ï¼Œè®¾ç½® 1.5s é—´éš”
        time.sleep(1.5)
        res = requests.get(f"http://ip-api.com/json/{ip}?lang=zh-CN", timeout=5).json()
        if res.get('status') == 'success':
            info = f"{res.get('city','æœªçŸ¥')} | {res.get('isp','æœªçŸ¥')}"
            IP_CACHE[ip] = info
            return info
    except:
        pass
    return "æœªçŸ¥ä½ç½® | æœªçŸ¥ç½‘ç»œ"

def probe_stream_detail(url):
    """ä½¿ç”¨ ffprobe è·å–æµè¯¦æƒ…ï¼ˆåˆ†è¾¨ç‡ã€ç¼–ç ï¼‰"""
    # æ¨¡æ‹Ÿä½ æä¾›çš„ç¨‹åºï¼šå¢åŠ æ¢æµ‹ç¼“å­˜å¤§å°è®¾ç½®ï¼Œæé«˜æ¢æµ‹æˆåŠŸç‡
    cmd = [
        'ffprobe', '-v', 'error', '-print_format', 'json', '-show_streams', 
        '-select_streams', 'v:0', '-probesize', '5000000', 
        '-analyzeduration', '5000000', '-i', url
    ]
    try:
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=12)
        if result.returncode == 0:
            data = json.loads(result.stdout)
            if 'streams' in data and len(data['streams']) > 0:
                v = data['streams'][0]
                return f"{v.get('width','?')}x{v.get('height','?')}"
    except:
        pass
    return None

def test_link_quality(line):
    """
    å…¨æ–¹ä½æµ‹è¯•é“¾æ¥è´¨é‡:
    1. å“åº”å»¶è¿Ÿ (Latency)
    2. ä¸‹è½½å¸¦å®½ (Speed)
    3. è§†é¢‘è¯¦æƒ… (ffprobe)
    4. åœ°ç†ä½ç½® (Geolocation)
    """
    if "," not in line: return False, line, "æ— æ•ˆè¡Œ"
    name, url = line.split(",", 1)
    
    try:
        # --- æµ‹å»¶è¿Ÿ (Latency) ---
        start_time = time.time()
        # allow_redirects=True å¤„ç†æŸäº›è·³è½¬æº
        resp = requests.get(url, stream=True, timeout=8, allow_redirects=True)
        latency = int((time.time() - start_time) * 1000)
        
        # --- æµ‹é€Ÿåº¦ (Speed) ---
        # ä¸‹è½½ 2 ç§’é’Ÿçš„æ•°æ®æ¥è®¡ç®—å¸¦å®½
        total_data = 0
        speed_start = time.time()
        for chunk in resp.iter_content(chunk_size=1024*256):
            total_data += len(chunk)
            if time.time() - speed_start > 2: # æµ‹é€Ÿ 2 ç§’
                break
        duration = time.time() - speed_start
        speed = round((total_data * 8) / (duration * 1024 * 1024), 2)
        resp.close()

        # --- æµ‹è§†é¢‘è¯¦æƒ… ---
        resolution = probe_stream_detail(url)
        if not resolution:
            return False, line, f"âŒ {name} | å¤±è´¥ | æ— æ³•è§£æè§†é¢‘æµ"

        # --- è·å–åœ°ç†ä½ç½® ---
        geo_info = get_ip_info(url)
        
        log_msg = f"âœ… {name} | {resolution} | å»¶è¿Ÿ:{latency}ms | é€Ÿåº¦:{speed}Mbps | {geo_info}"
        return True, line, log_msg

    except Exception as e:
        return False, line, f"âŒ {name} | å¤±è´¥ | è¿æ¥é”™è¯¯: {str(e)}"

# ===============================
# 3. è¿è¡Œé€»è¾‘
# ===============================

if __name__ == "__main__":
    print(f"\n{'='*20} å¯åŠ¨æ·±åº¦è´¨é‡æ¢æµ‹ {'='*20}")
    
    if not os.path.exists(SOURCE_M3U_FILE):
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {SOURCE_M3U_FILE}")
        exit()

    with open(SOURCE_M3U_FILE, encoding="utf-8") as f:
        lines = [l.strip() for l in f if "," in l]

    if not lines:
        print("âš ï¸ å¾…æµ‹åˆ—è¡¨ä¸ºç©ºã€‚")
        exit()

    print(f"ğŸ¬ å…± {len(lines)} æ¡é“¾æ¥ï¼Œé‡‡ç”¨å¤šçº¿ç¨‹æµ‹é€Ÿä¸æ¢æµ‹...")
    valid_results = []
    log_entries = []

    # GitHub Actions ç¯å¢ƒä¸‹å»ºè®® 5-8 çº¿ç¨‹ï¼Œé˜²æ­¢ç¬é—´å¸¦å®½è¿‡è½½
    with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:
        futures = [executor.submit(test_link_quality, l) for l in lines]
        for f in concurrent.futures.as_completed(futures):
            success, line, log_msg = f.result()
            print(log_msg)
            log_entries.append(log_msg)
            if success:
                valid_results.append(line)

    # ç»“æœæŒä¹…åŒ–
    print(f"\n{'='*20} æ¢æµ‹ç»“æœæ±‡æ€» {'='*20}")
    print(f"ğŸ“Š æ€»æ•°: {len(lines)} | æœ‰æ•ˆ: {len(valid_results)} | å¤±è´¥: {len(lines)-len(valid_results)}")

    with open(LOG_FILE, "w", encoding="utf-8") as f:
        f.write(f"æ¢æµ‹æŠ¥å‘Š | æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("-" * 60 + "\n")
        f.write("\n".join(sorted(log_entries)))

    with open(SOURCE_M3U_FILE, "w", encoding="utf-8") as f:
        f.write("\n".join(sorted(valid_results)))

    # å¦‚æœæœ‰æˆåŠŸç»“æœï¼Œåˆ™è§¦å‘è”åŠ¨
    if valid_results and TRIGGER_TOKEN:
        print(f"ğŸš€ æ­£åœ¨è§¦å‘è¿œç¨‹è”åŠ¨: {TARGET_REPO}")
        try:
            dispatch_url = f"https://api.github.com/repos/{TARGET_REPO}/actions/workflows/{TARGET_WORKFLOW}/dispatches"
            r = requests.post(
                dispatch_url, 
                headers={"Authorization": f"token {TRIGGER_TOKEN}", "Accept": "application/vnd.github.v3+json"},
                json={"ref": "main"}
            )
            print(f"   API å“åº”: {r.status_code}")
        except:
            print("   âš ï¸ è”åŠ¨è¯·æ±‚å¤±è´¥")
