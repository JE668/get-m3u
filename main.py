import os, re, requests, time, concurrent.futures
from datetime import datetime
from collections import Counter

# ===============================
# 1. é…ç½®åŒº
# ===============================
# ç‹™å‡» C æ®µ (æ ¹æ®ä½ æä¾›çš„æœ‰æ•ˆ IP è½¬æ¢)
TARGET_C_SEGMENTS = [
    "106.111.127", "113.95.140", "116.30.197", "121.33.112", 
    "14.145.163", "183.30.202", "183.31.11", "59.35.244", 
    "61.146.190", "113.102.18"
]
# æ•´åˆä½ å‘ç°çš„å…¨éƒ¨æœ‰æ•ˆç«¯å£
SCAN_PORTS = [4022, 8000, 8686, 55555, 54321, 1024, 10001, 8443, 8888]

FOFA_URL = "https://fofa.info/result?qbase64=IlVEUFhZIiAmJiBjb3VudHJ5PSJDTiIgJiYgcmVnaW9uPSJHdWFuZ2Rvbmci"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
    "Cookie": os.environ.get("FOFA_COOKIE", "") 
}
RTP_FILE = os.path.join("rtp", "ChinaTelecom-Guangdong.txt")
SOURCE_IP_FILE, SOURCE_M3U_FILE, SOURCE_NONCHECK_FILE = "source-ip.txt", "source-m3u.txt", "source-m3u-noncheck.txt"

def log_section(name, icon="ğŸ”¹"):
    print(f"\n{icon} {'='*15} {name} {'='*15}")

# ===============================
# 2. èµ„æºè·å–æ¨¡å—
# ===============================

def scrape_fofa():
    log_section("æŠ“å– FOFA èµ„æº", "ğŸ“¡")
    if not HEADERS["Cookie"]: 
        print("  â­ï¸  æœªé…ç½® Cookieï¼Œè·³è¿‡ FOFAã€‚")
        return []
    try:
        r = requests.get(FOFA_URL, headers=HEADERS, timeout=15)
        if "è´¦å·ç™»å½•" in r.text:
            print("  âŒ FOFA Cookie å·²å¤±æ•ˆï¼")
            return []
        
        raw_list = re.findall(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d+)', r.text)
        if raw_list:
            counts = Counter(raw_list)
            print(f"  âœ… FOFA åŸå§‹æ•°æ®: æ‰¾åˆ° {len(raw_list)} æ¡è®°å½•")
            print("  ğŸ“œ [å”¯ä¸€ IP åˆ—è¡¨åŠå‡ºç°æ¬¡æ•°]:")
            unique_ips = sorted(counts.keys())
            for ip in unique_ips:
                print(f"    - {ip:<25} (å‡ºç° {counts[ip]} æ¬¡)")
            return unique_ips
        return []
    except: return []

def check_udpxy_fingerprint(ip_port):
    """æŒ‡çº¹è¯†åˆ«: æ£€æŸ¥æ˜¯å¦ä¸ºçœŸå®çš„ udpxy æœåŠ¡"""
    for path in ["/stat", "/status"]:
        try:
            url = f"http://{ip_port}{path}"
            r = requests.get(url, timeout=2, headers={"User-Agent":"Wget/1.14"})
            if r.status_code == 200 and any(kw in r.text.lower() for kw in ["udpxy", "stat", "client"]):
                return True
        except: continue
    return False

def run_native_scan():
    log_section("å¯åŠ¨å®šå‘ C æ®µç‹™å‡»æ‰«æ", "ğŸš€")
    print(f"  ğŸ“¡ ç›®æ ‡: {len(TARGET_C_SEGMENTS)} ä¸ª C æ®µ | ç«¯å£: {SCAN_PORTS}")
    found_ips = []
    
    # æ„å»ºå¾…æµ‹ä»»åŠ¡åˆ—è¡¨ (Cæ®µ 254å°ä¸»æœº * Nä¸ªç«¯å£)
    tasks = []
    for seg in TARGET_C_SEGMENTS:
        for i in range(1, 255):
            ip = f"{seg}.{i}"
            for port in SCAN_PORTS:
                tasks.append(f"{ip}:{port}")

    print(f"  âš¡ æ­£åœ¨å¹¶è¡Œæ¢æµ‹ {len(tasks)} ä¸ªæ½œåœ¨ç»„åˆ...")
    
    # ä½¿ç”¨å¤šçº¿ç¨‹è¿›è¡Œ HTTP æŒ‡çº¹æ¢æµ‹
    with concurrent.futures.ThreadPoolExecutor(max_workers=200) as executor:
        future_to_ip = {executor.submit(check_udpxy_fingerprint, ip): ip for ip in tasks}
        for future in concurrent.futures.as_completed(future_to_ip):
            ip_port = future_to_ip[future]
            if future.result():
                print(f"    ğŸŒŸ å‘ç°ç›®æ ‡: {ip_port}")
                found_ips.append(ip_port)
                
    print(f"  âœ… æ‰«æç»“æŸ | å‘ç° {len(found_ips)} ä¸ªåœ¨çº¿ udpxy èŠ‚ç‚¹")
    return found_ips

# ===============================
# 3. æ ¡éªŒä¸å¤„ç†æ¨¡å—
# ===============================

def update_rtp_template():
    log_section("åŒæ­¥å¹¶æ›´æ–° RTP æ¨¡æ¿", "ğŸ”„")
    os.makedirs("rtp", exist_ok=True)
    unique_rtp = {}
    sources = [
        "https://raw.githubusercontent.com/Tzwcard/ChinaTelecom-GuangdongIPTV-RTP-List/refs/heads/master/GuangdongIPTV_rtp_4k.m3u",
        "https://raw.githubusercontent.com/Tzwcard/ChinaTelecom-GuangdongIPTV-RTP-List/refs/heads/master/GuangdongIPTV_rtp_hd.m3u"
    ]
    for url in sources:
        try:
            r = requests.get(url, timeout=15)
            r.encoding = 'utf-8'
            if r.status_code == 200:
                lines = r.text.splitlines()
                for i in range(len(lines)):
                    if lines[i].startswith("#EXTINF"):
                        name = lines[i].split(',')[-1].strip()
                        for j in range(i + 1, min(i + 5, len(lines))):
                            if lines[j].strip().startswith("rtp://"):
                                unique_rtp[lines[j].strip()] = name
                                break
        except: pass
    if unique_rtp:
        with open(RTP_FILE, "w", encoding="utf-8") as f:
            for url, name in unique_rtp.items(): f.write(f"{name},{url}\n")
        print(f"ğŸ“Š ç»Ÿè®¡: RTP æ¨¡æ¿æ›´æ–°å®Œæ¯• | å…± {len(unique_rtp)} ä¸ªé¢‘é“")

def verify_geo(ip_port):
    try:
        ip = ip_port.split(":")[0]
        res = requests.get(f"http://ip-api.com/json/{ip}?lang=zh-CN", timeout=10).json()
        if res.get("status") != "success": return False, f"{ip_port:<21} | æŸ¥è¯¢å¤±è´¥"
        reg, city, isp = res.get("regionName","æœªçŸ¥"), res.get("city","æœªçŸ¥"), res.get("isp","æœªçŸ¥")
        is_gd = "å¹¿ä¸œ" in reg
        is_tel = any(kw in isp.lower() for kw in ["ç”µä¿¡", "telecom", "chinanet"])
        info = f"{ip_port:<21} | {reg} - {city} | {isp}"
        return (is_gd and is_tel), info
    except: return False, f"{ip_port:<21} | å¼‚å¸¸"

if __name__ == "__main__":
    start_time = time.time()
    update_rtp_template()

    # 1. æ··åˆé‡‡é›†
    fofa_ips = scrape_fofa()
    scanned_ips = run_native_scan()
    
    unique_raw = sorted(list(set(fofa_ips + scanned_ips)))
    print(f"\nğŸ“Š æ±‡æ€»ç»Ÿè®¡: FOFA ({len(fofa_ips)}) + æ‰«æ ({len(scanned_ips)}) -> å»é‡åæ€»è®¡ {len(unique_raw)} ä¸ªç‹¬ç«‹ IP")

    # 2. åœ°ç†æ ¡éªŒ
    log_section("åœ°ç†å½’å±åœ°æ ¡éªŒ (å¹¿ä¸œç”µä¿¡)", "ğŸŒ")
    geo_ips = []
    for idx, ip_port in enumerate(unique_raw, 1):
        ok, desc = verify_geo(ip_port)
        status = "âœ… åŒ¹é…" if ok else "â­ï¸ è·³è¿‡"
        print(f"  [{idx:02d}/{len(unique_raw):02d}] {status} | {desc}")
        if ok: geo_ips.append(ip_port)
        time.sleep(1.2)

    # 3. ç»“æœä¿å­˜
    log_section("æ•°æ®å½’æ¡£ä¸æ‹¼è£…", "ğŸ’¾")
    if geo_ips:
        geo_ips.sort()
        with open(SOURCE_IP_FILE, "w", encoding="utf-8") as f: f.write("\n".join(geo_ips))
        if os.path.exists(RTP_FILE):
            with open(RTP_FILE, encoding="utf-8") as f: rtps = [x.strip() for x in f if "," in x]
            m3u = [f"{r.split(',')[0]},http://{ip}/rtp/{r.split('://')[1]}" for ip in geo_ips for r in rtps]
            for fpath in [SOURCE_NONCHECK_FILE, SOURCE_M3U_FILE]:
                with open(fpath, "w", encoding="utf-8") as f: f.write("\n".join(m3u))
            print(f"âœ¨ æŠ¥å‘Š: æœ‰æ•ˆæœåŠ¡å™¨ {len(geo_ips)} ä¸ª | æ‹¼è£…é“¾æ¥ {len(m3u)} æ¡")
    else: print("âŒ ç»ˆæ­¢: æœªå‘ç°ç¬¦åˆæ¡ä»¶çš„èŠ‚ç‚¹")
    
    print(f"\nâ±ï¸ æ€»è€—æ—¶: {round(time.time() - start_time, 2)}s")
