import os, re, requests, time, concurrent.futures
from datetime import datetime

# ===============================
# é…ç½®åŒº
# ===============================
# æœç´¢å…³é”®è¯
SEARCH_KEYWORD = "å¹¿ä¸œç”µä¿¡"

# å…ç™»å½•æœç´¢å¼•æ“é…ç½® (Tonkiang)
TONKIANG_URL = "https://tonkiang.us/?i=" + SEARCH_KEYWORD

# FOFA é…ç½® (ä¿ç•™ä½œä¸ºå¤‡é€‰ï¼Œè‹¥Cookieå¤±æ•ˆä¼šè‡ªåŠ¨è·³è¿‡)
# å¸¦åŸå¸‚ç­›é€‰
# FOFA_URL = "https://fofa.info/result?qbase64=IlVEUFhZIiAmJiBjb3VudHJ5PSJDTiIgJiYgcmVnaW9uPSJHdWFuZ2RvbmciICYmIGNpdHk9Ilpob25nc2hhbiI%3D"

# ä¸å¸¦åŸå¸‚ç­›é€‰
FOFA_URL = "https://fofa.info/result?qbase64=IlVEUFhZIiAmJiBjb3VudHJ5PSJDTiIgJiYgcmVnaW9uPSJHdWFuZ2Rvbmci&filter_type=last_month"
# FOFA_URL = "https://fofa.info/result?qbase64=IlVEUFhZIiAmJiBjb3VudHJ5PSJDTiIgJiYgcmVnaW9uPSJHdWFuZ2RvbmciICYmIGNpdHk9Ilpob25nc2hhbiI="
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Cookie": os.environ.get("FOFA_COOKIE", ""),
    "Referer": "https://tonkiang.us/"
}

RTP_SOURCES = [
    "https://raw.githubusercontent.com/Tzwcard/ChinaTelecom-GuangdongIPTV-RTP-List/refs/heads/master/GuangdongIPTV_rtp_4k.m3u",
    "https://raw.githubusercontent.com/Tzwcard/ChinaTelecom-GuangdongIPTV-RTP-List/refs/heads/master/GuangdongIPTV_rtp_hd.m3u"
]
RTP_FILE = os.path.join("rtp", "ChinaTelecom-Guangdong.txt")
SOURCE_IP_FILE, SOURCE_M3U_FILE, SOURCE_NONCHECK_FILE = "source-ip.txt", "source-m3u.txt", "source-m3u-noncheck.txt"

def log_section(name, icon="ğŸ”¹"):
    print(f"\n{icon} {'='*15} {name} {'='*15}")

def update_rtp_template():
    log_section("åŒæ­¥å¹¶æ›´æ–° RTP æ¨¡æ¿", "ğŸ”„")
    os.makedirs("rtp", exist_ok=True)
    unique_rtp = {}
    for url in RTP_SOURCES:
        try:
            r = requests.get(url, timeout=15)
            r.encoding = 'utf-8'
            if r.status_code == 200:
                lines = r.text.splitlines()
                count = 0
                for i in range(len(lines)):
                    if lines[i].startswith("#EXTINF"):
                        name = lines[i].split(',')[-1].strip()
                        for j in range(i + 1, min(i + 5, len(lines))):
                            if lines[j].strip().startswith("rtp://"):
                                if lines[j].strip() not in unique_rtp:
                                    unique_rtp[lines[j].strip()] = name
                                    count += 1
                                break
                print(f"  ğŸ“¥ {url.split('/')[-1]} | è§£ææˆåŠŸ | æå– {count} æ¡")
        except: print(f"  âŒ åŒæ­¥å¤±è´¥: {url.split('/')[-1]}")
    if unique_rtp:
        with open(RTP_FILE, "w", encoding="utf-8") as f:
            for url, name in unique_rtp.items(): f.write(f"{name},{url}\n")
        print(f"ğŸ“Š ç»Ÿè®¡: RTP æ¨¡æ¿æ›´æ–°å®Œæ¯• | å…± {len(unique_rtp)} ä¸ªé¢‘é“")

def scrape_tonkiang():
    """å…ç™»å½•ä» Tonkiang çˆ¬å– IP"""
    log_section("ä» Tonkiang æ£€ç´¢èµ„æº (å…ç™»å½•)", "ğŸ”")
    found_ips = []
    try:
        r = requests.get(TONKIANG_URL, headers=HEADERS, timeout=15)
        if r.status_code == 200:
            # åŒ¹é… IP:ç«¯å£ æ ¼å¼
            found_ips = re.findall(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d+)', r.text)
            print(f"  âœ… Tonkiang å“åº”æˆåŠŸ | æå–åˆ° {len(found_ips)} ä¸ªæ½œåœ¨ IP")
        else:
            print(f"  âŒ Tonkiang è®¿é—®å¤±è´¥ | çŠ¶æ€ç : {r.status_code}")
    except Exception as e:
        print(f"  âŒ Tonkiang å¼‚å¸¸: {e}")
    return found_ips

def scrape_fofa():
    """ä» FOFA çˆ¬å– IP"""
    if not HEADERS["Cookie"]:
        return []
    log_section("ä» FOFA æ£€ç´¢èµ„æº", "ğŸ“¡")
    found_ips = []
    try:
        r = requests.get(FOFA_URL, headers=HEADERS, timeout=15)
        if "è´¦å·ç™»å½•" in r.text or "ç™»å½•åå¯è§" in r.text:
            print("  âš ï¸ FOFA Cookie å·²å¤±æ•ˆï¼Œè·³è¿‡æ­¤æºã€‚")
            return []
        found_ips = re.findall(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d+)', r.text)
        print(f"  âœ… FOFA å“åº”æˆåŠŸ | æå–åˆ° {len(found_ips)} ä¸ªæ½œåœ¨ IP")
    except:
        print("  âŒ FOFA è®¿é—®å¼‚å¸¸")
    return found_ips

def verify_geo(ip_port):
    try:
        ip = ip_port.split(":")[0]
        url = f"http://ip-api.com/json/{ip}?lang=zh-CN"
        res = requests.get(url, timeout=10).json()
        if res.get("status") != "success": return False, f"{ip_port} | æŸ¥è¯¢å¤±è´¥"
        region, city, isp = res.get("regionName","æœªçŸ¥"), res.get("city","æœªçŸ¥"), res.get("isp","æœªçŸ¥")
        is_gd = "å¹¿ä¸œ" in region
        is_telecom = any(kw in isp.lower() for kw in ["ç”µä¿¡", "telecom", "chinanet"])
        info = f"{ip_port} | {region} - {city} | {isp}"
        return (is_gd and is_telecom), info
    except: return False, f"{ip_port} | ç½‘ç»œå¼‚å¸¸"

def check_status(ip_port):
    for path in ["/stat", "/status"]:
        try:
            r = requests.get(f"http://{ip_port}{path}", timeout=4)
            if r.status_code == 200 and any(kw in r.text.lower() for kw in ["udpxy", "stat", "client"]):
                return True
        except: continue
    return False

if __name__ == "__main__":
    start_time = time.time()
    update_rtp_template()

    # 1. æ±‡æ€»å¤šæºæ•°æ®
    ips_tonkiang = scrape_tonkiang()
    ips_fofa = scrape_fofa()
    unique_raw = sorted(list(set(ips_tonkiang + ips_fofa)))
    print(f"\nğŸ“Š èµ„æºæ±‡æ€»: æ€»å…±è·å–åˆ° {len(unique_raw)} ä¸ªå”¯ä¸€ IP")

    # 2. åœ°ç†æ ¡éªŒ
    log_section("åœ°ç†å½’å±åœ°æ ¡éªŒ (å¹¿ä¸œç”µä¿¡)", "ğŸŒ")
    geo_ips = []
    total = len(unique_raw)
    for idx, ip_port in enumerate(unique_raw, 1):
        ok, desc = verify_geo(ip_port)
        status = "âœ… åŒ¹é…" if ok else "â­ï¸ è·³è¿‡"
        print(f"  [{idx:02d}/{total:02d}] {status} | {desc}")
        if ok: geo_ips.append(ip_port)
        time.sleep(1.2)

    # 3. Web çŠ¶æ€æ¢æµ‹
    log_section("Web æ¥å£åœ¨çº¿æ£€æµ‹ (UDPXY)", "ğŸ”")
    online_ips = []
    if geo_ips:
        with concurrent.futures.ThreadPoolExecutor(max_workers=15) as ex:
            futures = {ex.submit(check_status, ip): ip for ip in geo_ips}
            for f in concurrent.futures.as_completed(futures):
                ip = futures[f]
                if f.result():
                    print(f"  ğŸŸ¢ åœ¨çº¿ | {ip}"); online_ips.append(ip)
                else: print(f"  ğŸ”´ ç¦»çº¿ | {ip}")

    # 4. æ•°æ®ä¿å­˜
    log_section("æ•°æ®å½’æ¡£ä¸æ‹¼è£…", "ğŸ’¾")
    if online_ips:
        online_ips.sort()
        with open(SOURCE_IP_FILE, "w", encoding="utf-8") as f: f.write("\n".join(online_ips))
        if os.path.exists(RTP_FILE):
            with open(RTP_FILE, encoding="utf-8") as f: rtps = [x.strip() for x in f if "," in x]
            m3u = [f"{r.split(',')[0]},http://{ip}/rtp/{r.split('://')[1]}" for ip in online_ips for r in rtps]
            for fpath in [SOURCE_NONCHECK_FILE, SOURCE_M3U_FILE]:
                with open(fpath, "w", encoding="utf-8") as f: f.write("\n".join(m3u))
            print(f"âœ¨ æŠ¥å‘Š: æœ‰æ•ˆæœåŠ¡å™¨ {len(online_ips)} ä¸ª | æ’­æ”¾é“¾æ¥ {len(m3u)} æ¡")
    else: print("âŒ ç»ˆæ­¢: æœªå‘ç°å¯ç”¨åœ¨çº¿æ¥å£")
    print(f"\nâ±ï¸ æ€»è€—æ—¶: {round(time.time() - start_time, 2)}s")
